{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akira Kurosawa\n",
      "33 credits\n",
      "Maadadayo,1993\n",
      "Hachi-gatsu no rapusodî,1991\n",
      "Yume,1990\n",
      "Ran,1985\n",
      "Kagemusha,1980\n",
      "Dersu Uzala,1975\n",
      "Dodesukaden,1970\n",
      "Uma no uta,1970\n",
      "Akahige,1965\n",
      "Tengoku to jigoku,1963\n",
      "Sanjuro,1962\n",
      "Yôjinbô,1961\n",
      "Warui yatsu hodo yoku nemuru,1960\n",
      "Kakushi-toride no san-akunin,1958\n",
      "Donzoko,1957\n",
      "Kumonosu-jô,1957\n",
      "Ikimono no kiroku,1955\n",
      "Shichinin no samurai,1954\n",
      "Ikiru,1952\n",
      "Hakuchi,1951\n",
      "Rashômon,1950\n",
      "Shûbun,1950\n",
      "Nora inu,1949\n",
      "Shizukanaru kettô,1949\n",
      "Yoidore tenshi,1948\n",
      "Subarashiki nichiyôbi,1947\n",
      "Waga seishun ni kuinashi,1946\n",
      "Asu o tsukuru hitobito,1946\n",
      "Tora no o wo fumu otokotachi,1945\n",
      "Zoku Sugata Sanshirô,1945\n",
      "Ichiban utsukushiku,1944\n",
      "Sugata Sanshirô,1943\n",
      "Uma,1941\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_url(director):\n",
    "    url = 'https://www.imdb.com/find?q=%s&s=nm&ref_=fn_nm' % director\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    link = soup.find_all('td', {'class':'result_text'})[0].find('a')['href']\n",
    "    url = 'https://www.imdb.com/' + link\n",
    "    return url\n",
    "\n",
    "def get_movie(url):\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    number = soup.find_all('div', {'data-category':'director'})[-1].text\n",
    "    left = number.index('(')\n",
    "    right = number.index(')')\n",
    "    number = number[left+1:right]\n",
    "    filmography = soup.find('div', {'id':'filmography'})\n",
    "    for i in filmography.find_all('div', {'class':'filmo-category-section'}):\n",
    "        if 'id=\"director' in str(i):\n",
    "            director = i\n",
    "    name_list = list()\n",
    "    year_list = list()\n",
    "    movie_list = list()\n",
    "    for i in director.find_all('b'):\n",
    "        name_list.append(i.text)\n",
    "    for i in director.find_all('span', {'class':'year_column'}):\n",
    "        i = i.text\n",
    "        i = i.replace('\\n', '')[1:]\n",
    "        year_list.append(i)\n",
    "    for i, j in zip (name_list, year_list):\n",
    "        movie_list.append([i, j])\n",
    "    return number, movie_list\n",
    "\n",
    "director = input()\n",
    "url = get_url(director)\n",
    "number, movie_list = get_movie(url)\n",
    "print(number)\n",
    "for i in movie_list:\n",
    "    if i[1] == '':\n",
    "        print('%s' % (i[0]))\n",
    "    else:\n",
    "        print('%s,%s' % (i[0], i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
